"""
Auto-generated merged function_app.py for multi-function Azure Function bundle.

This file was generated by function_bundler.py to combine multiple functions
into a single function_app.py as required by Azure Functions v2.

Functions included: persister, event-checker
"""
from _shared.env_utils import require_env
from _shared.inter_cloud import post_to_remote
from azure.cosmos import CosmosClient, PartitionKey
from azure.digitaltwins.core import DigitalTwinsClient
from azure.identity import DefaultAzureCredential
import azure.functions as func
import json
import logging
import os
import sys
import urllib.error
import urllib.request

# Create the single Function App instance
app = func.FunctionApp()


# === Code from persister ===
"""
Persister Azure Function.

Persists processed device data to storage. In single-cloud mode,
writes directly to Cosmos DB. In multi-cloud mode, POSTs to remote
Hot Writer.

Architecture:
    Processor → Persister → Cosmos DB (or Remote Hot Writer)

Source: src/providers/azure/azure_functions/persister/function_app.py
Editable: Yes - This is the runtime Azure Function code
"""




class ConfigurationError(Exception):
    """Raised when multi-cloud configuration is invalid."""
    pass


# DIGITAL_TWIN_INFO is lazy-loaded to allow Azure function discovery
# (module-level require_env would fail during import if env var is missing)
_digital_twin_info = None

def _get_digital_twin_info():
    """Lazy-load DIGITAL_TWIN_INFO to avoid import-time failures."""
    global _digital_twin_info
    if _digital_twin_info is None:
        _digital_twin_info = json.loads(require_env("DIGITAL_TWIN_INFO"))
    return _digital_twin_info

# Cosmos DB config (for single-cloud mode)
COSMOS_DB_ENDPOINT = os.environ.get("COSMOS_DB_ENDPOINT", "").strip()
COSMOS_DB_KEY = os.environ.get("COSMOS_DB_KEY", "").strip()
COSMOS_DB_DATABASE = os.environ.get("COSMOS_DB_DATABASE", "").strip()
COSMOS_DB_CONTAINER = os.environ.get("COSMOS_DB_CONTAINER", "").strip()

# Multi-cloud config (optional)
REMOTE_WRITER_URL = os.environ.get("REMOTE_WRITER_URL", "").strip()
INTER_CLOUD_TOKEN = os.environ.get("INTER_CLOUD_TOKEN", "").strip()

# ADT Pusher config (for multi-cloud L4 - L2 != L4 and L4 = Azure)
REMOTE_ADT_PUSHER_URL = os.environ.get("REMOTE_ADT_PUSHER_URL", "").strip()
ADT_PUSHER_TOKEN = os.environ.get("ADT_PUSHER_TOKEN", "").strip()

# Event checking config (optional)
EVENT_CHECKER_FUNCTION_URL = os.environ.get("EVENT_CHECKER_FUNCTION_URL", "").strip()
USE_EVENT_CHECKING = os.environ.get("USE_EVENT_CHECKING", "false").lower() == "true"

# Function base URL for invoking other functions
FUNCTION_APP_BASE_URL = os.environ.get("FUNCTION_APP_BASE_URL", "").strip()

# Cosmos DB client (lazy initialized)
_cosmos_container = None

# Create Function App instance


def _get_cosmos_container():
    """Lazy initialization of Cosmos DB container."""
    global _cosmos_container
    if _cosmos_container is None:
        if not all([COSMOS_DB_ENDPOINT, COSMOS_DB_KEY, COSMOS_DB_DATABASE, COSMOS_DB_CONTAINER]):
            raise ConfigurationError("Cosmos DB configuration incomplete for single-cloud mode")
        
        client = CosmosClient(COSMOS_DB_ENDPOINT, credential=COSMOS_DB_KEY)
        database = client.get_database_client(COSMOS_DB_DATABASE)
        _cosmos_container = database.get_container_client(COSMOS_DB_CONTAINER)
    
    return _cosmos_container


def _is_multi_cloud_storage() -> bool:
    """
    Check if L2 and L3 Hot are on different cloud providers.
    
    Returns True only if:
    1. REMOTE_WRITER_URL is set AND non-empty
    2. layer_2_provider != layer_3_hot_provider
    """
    if not REMOTE_WRITER_URL:
        return False
    
    providers = DIGITAL_TWIN_INFO.get("config_providers")
    if providers is None:
        raise ConfigurationError(
            "CRITICAL: 'config_providers' missing from DIGITAL_TWIN_INFO."
        )
    
    l2_provider = providers.get("layer_2_provider")
    l3_provider = providers.get("layer_3_hot_provider")
    
    if l2_provider is None or l3_provider is None:
        raise ConfigurationError(
            f"CRITICAL: Missing provider mapping. "
            f"layer_2_provider={l2_provider}, layer_3_hot_provider={l3_provider}"
        )
    
    if l2_provider == l3_provider:
        logging.warning(f"REMOTE_WRITER_URL set but providers match ({l2_provider}). Using local Cosmos DB.")
        return False
    
    return True


def _invoke_event_checker(event: dict) -> None:
    """Invoke Event Checker function via HTTP POST."""
    if not EVENT_CHECKER_FUNCTION_URL:
        logging.warning("EVENT_CHECKER_FUNCTION_URL not set - cannot invoke Event Checker")
        return
    
    data = json.dumps(event).encode("utf-8")
    headers = {"Content-Type": "application/json"}
    req = urllib.request.Request(EVENT_CHECKER_FUNCTION_URL, data=data, headers=headers, method="POST")
    
    try:
        with urllib.request.urlopen(req, timeout=30) as response:
            logging.info(f"Event Checker invoked: {response.getcode()}")
    except Exception as e:
        logging.warning(f"Failed to invoke Event Checker: {e}")
        # Don't fail persister if event checker fails


def _should_push_to_adt() -> bool:
    """
    Check if we should push data to remote ADT Pusher.
    
    Returns True only if:
    1. REMOTE_ADT_PUSHER_URL is set AND non-empty
    2. ADT_PUSHER_TOKEN is set AND non-empty
    
    ADT push is for multi-cloud L4 scenarios where L2 != L4 and L4 = Azure.
    """
    return bool(REMOTE_ADT_PUSHER_URL and ADT_PUSHER_TOKEN)


def _push_to_adt(event: dict) -> None:
    """
    Push telemetry to remote ADT Pusher (L4 Multi-Cloud).
    
    This is called IN ADDITION TO storage persist, not instead of it.
    Failures are logged but don't fail the overall persist operation.
    
    Args:
        event: Original telemetry event (with 'time' field)
    """
    if not _should_push_to_adt():
        return
    
    logging.info(f"Pushing to ADT Pusher at {REMOTE_ADT_PUSHER_URL}")
    
    try:
        # Build ADT push payload
        adt_payload = {
            "device_id": event.get("device_id"),
            "device_type": event.get("device_type"),
            "telemetry": event.get("telemetry", {}),
            "timestamp": event.get("time")
        }
        
        result = post_to_remote(
            url=REMOTE_ADT_PUSHER_URL,
            token=ADT_PUSHER_TOKEN,
            payload=adt_payload,
            target_layer="L4"
        )
        logging.info(f"ADT push successful: {result}")
    except Exception as e:
        # Log but don't fail - ADT is secondary to storage
        logging.warning(f"ADT push failed (non-fatal): {e}")


@app.function_name(name="persister")
@app.route(route="persister", methods=["POST"], auth_level=func.AuthLevel.FUNCTION)
def persister(req: func.HttpRequest) -> func.HttpResponse:
    """
    Persist processed data to storage.
    
    Routes to either local Cosmos DB or remote Hot Writer
    based on multi-cloud configuration.
    """
    logging.info("Azure Persister: Received request")
    
    try:
        # Parse input data
        event = req.get_json()
        logging.info(f"Event: {json.dumps(event)}")
        
        # Validate required field
        if "time" not in event:
            return func.HttpResponse(
                json.dumps({"error": "Missing 'time' in event"}),
                status_code=400,
                mimetype="application/json"
            )
        
        # Build storage item (Cosmos DB requires 'id' as primary key)
        item = event.copy()
        item["id"] = str(item.pop("time"))
        
        # Route based on multi-cloud config
        if _is_multi_cloud_storage():
            logging.info(f"Multi-cloud mode: POSTing to {REMOTE_WRITER_URL}")
            
            if not INTER_CLOUD_TOKEN:
                raise ConfigurationError("INTER_CLOUD_TOKEN required for multi-cloud mode")
            
            result = post_to_remote(
                url=REMOTE_WRITER_URL,
                token=INTER_CLOUD_TOKEN,
                payload=item,
                target_layer="L3"
            )
            logging.info(f"Item persisted to remote cloud: {result}")
        else:
            # Single-cloud: Write to local Cosmos DB
            logging.info("Single-cloud mode: Writing to local Cosmos DB")
            container = _get_cosmos_container()
            container.upsert_item(item)
            logging.info("Item persisted to local Cosmos DB.")
        
        # Multi-cloud L4: Push to ADT Pusher (IN ADDITION to storage)
        # This is for scenarios where L2 != L4 and L4 = Azure
        _push_to_adt(event)
        
        # Optionally invoke Event Checker
        if USE_EVENT_CHECKING:
            _invoke_event_checker(event)
        
        return func.HttpResponse(
            json.dumps({"status": "persisted"}),
            status_code=200,
            mimetype="application/json"
        )
        
    except ConfigurationError as e:
        logging.error(f"Persister Configuration Error: {e}")
        return func.HttpResponse(
            json.dumps({"error": str(e)}),
            status_code=500,
            mimetype="application/json"
        )
        
    except Exception as e:
        logging.error(f"Persister Error: {e}")
        return func.HttpResponse(
            json.dumps({"error": str(e)}),
            status_code=500,
            mimetype="application/json"
        )


# === Code from event-checker ===
"""
Event Checker Azure Function.

Evaluates device data against configured thresholds and triggers
remediation workflows (Logic Apps) or feedback actions.

Architecture:
    Persister → Event Checker → Logic Apps / Azure Functions

Source: src/providers/azure/azure_functions/event-checker/function_app.py
Editable: Yes - This is the runtime Azure Function code
"""




# Required environment variables - fail fast if missing
DIGITAL_TWIN_INFO = json.loads(require_env("DIGITAL_TWIN_INFO"))

# Optional environment variables
ADT_INSTANCE_URL = os.environ.get("ADT_INSTANCE_URL", "").strip()
LOGIC_APP_TRIGGER_URL = os.environ.get("LOGIC_APP_TRIGGER_URL", "").strip()
FEEDBACK_FUNCTION_URL = os.environ.get("FEEDBACK_FUNCTION_URL", "").strip()
FUNCTION_APP_BASE_URL = os.environ.get("FUNCTION_APP_BASE_URL", "").strip()

USE_LOGIC_APPS = os.environ.get("USE_LOGIC_APPS", "false").lower() == "true"
USE_FEEDBACK = os.environ.get("USE_FEEDBACK", "false").lower() == "true"

# Create Function App instance

# ADT client (lazy initialized)
_adt_client = None


def _get_adt_client():
    """Lazy initialization of ADT client."""
    global _adt_client
    if _adt_client is None:
        if not ADT_INSTANCE_URL:
            raise ValueError("ADT_INSTANCE_URL is required for fetching ADT property values")
        credential = DefaultAzureCredential()
        _adt_client = DigitalTwinsClient(ADT_INSTANCE_URL, credential)
    return _adt_client


def fetch_value(entity_id: str, component_name: str, property_name: str):
    """
    Fetch property value from Azure Digital Twins.
    
    Equivalent to AWS TwinMaker get_property_value.
    
    Args:
        entity_id: Digital twin entity ID
        component_name: Component name
        property_name: Property to fetch
    
    Returns:
        Property value
    """
    client = _get_adt_client()
    
    # Get the digital twin
    twin = client.get_digital_twin(entity_id)
    
    # ADT stores component data in the twin properties
    # Component properties are typically nested under the component name
    if component_name in twin:
        component_data = twin[component_name]
        if property_name in component_data:
            return component_data[property_name]
    
    # Fallback: check top-level properties
    if property_name in twin:
        return twin[property_name]
    
    raise ValueError(f"Property {property_name} not found in entity {entity_id}")


def extract_const_value(string: str):
    """
    Extract typed constant value from condition string.
    
    Supports: DOUBLE(x), INTEGER(x), STRING(x)
    """
    if string.startswith("DOUBLE"):
        return float(string[7:-1])
    elif string.startswith("INTEGER"):
        return int(string[8:-1])
    elif string.startswith("STRING"):
        return string[7:-1]
    return string


def _trigger_logic_app(payload: dict) -> None:
    """Trigger Azure Logic App via HTTP POST."""
    if not LOGIC_APP_TRIGGER_URL:
        raise ValueError("LOGIC_APP_TRIGGER_URL is required")
    
    data = json.dumps(payload).encode("utf-8")
    headers = {"Content-Type": "application/json"}
    req = urllib.request.Request(LOGIC_APP_TRIGGER_URL, data=data, headers=headers, method="POST")
    
    try:
        with urllib.request.urlopen(req, timeout=30) as response:
            logging.info(f"Logic App triggered: {response.getcode()}")
    except urllib.error.HTTPError as e:
        logging.error(f"Failed to trigger Logic App: {e.code}")
        raise


def _invoke_function(function_name: str, payload: dict) -> None:
    """Invoke Azure Function via HTTP POST."""
    if not FUNCTION_APP_BASE_URL:
        logging.warning(f"FUNCTION_APP_BASE_URL not set - cannot invoke {function_name}")
        return
    
    url = f"{FUNCTION_APP_BASE_URL}/api/{function_name}"
    data = json.dumps(payload).encode("utf-8")
    headers = {"Content-Type": "application/json"}
    req = urllib.request.Request(url, data=data, headers=headers, method="POST")
    
    try:
        with urllib.request.urlopen(req, timeout=30) as response:
            logging.info(f"Function {function_name} invoked: {response.getcode()}")
    except urllib.error.HTTPError as e:
        logging.error(f"Failed to invoke {function_name}: {e.code}")
        raise


def _send_feedback(feedback_payload: dict) -> None:
    """Send feedback via HTTP POST."""
    if not FEEDBACK_FUNCTION_URL:
        raise ValueError("FEEDBACK_FUNCTION_URL is required")
    
    data = json.dumps(feedback_payload).encode("utf-8")
    headers = {"Content-Type": "application/json"}
    req = urllib.request.Request(FEEDBACK_FUNCTION_URL, data=data, headers=headers, method="POST")
    
    try:
        with urllib.request.urlopen(req, timeout=30) as response:
            logging.info(f"Feedback sent: {response.getcode()}")
    except urllib.error.HTTPError as e:
        logging.error(f"Failed to send feedback: {e.code}")
        raise


@app.function_name(name="event-checker")
@app.route(route="event-checker", methods=["POST"], auth_level=func.AuthLevel.FUNCTION)
def event_checker(req: func.HttpRequest) -> func.HttpResponse:
    """
    Evaluate data against configured event rules and trigger actions.
    """
    logging.info("Azure Event Checker: Checking events")
    
    try:
        event = req.get_json()
        logging.info(f"Event: {json.dumps(event)}")
        
        config_events = DIGITAL_TWIN_INFO.get("config_events", [])
        logging.info(f"Checking {len(config_events)} configured events")
        
        results = []
        
        for e in config_events:
            try:
                condition = e.get("condition", "")
                parts = condition.split()
                
                if len(parts) != 3:
                    logging.error(f"Invalid condition format: {condition}")
                    continue
                
                param1, operation, param2 = parts
                
                # Extract param1 value (property or constant)
                if len(param1.split(".")) > 1:
                    p1_parts = param1.split(".")
                    param1_value = fetch_value(p1_parts[0], p1_parts[1], p1_parts[2])
                else:
                    param1_value = extract_const_value(param1)
                
                # Extract param2 value (property or constant)
                if len(param2.split(".")) > 1:
                    p2_parts = param2.split(".")
                    param2_value = fetch_value(p2_parts[0], p2_parts[1], p2_parts[2])
                else:
                    param2_value = extract_const_value(param2)
                
                # Evaluate condition
                if operation == "<":
                    result = param1_value < param2_value
                elif operation == ">":
                    result = param1_value > param2_value
                elif operation == "==":
                    result = param1_value == param2_value
                else:
                    logging.error(f"Unknown operation: {operation}")
                    continue
                
                if result:
                    action_type = e.get("action", {}).get("type")
                    
                    # Handle Logic App action
                    if action_type == "logic_app" and USE_LOGIC_APPS:
                        _trigger_logic_app({"event": e})
                        results.append({"event": condition, "action": "logic_app_triggered"})
                    
                    # Handle function/lambda action
                    elif action_type in ("lambda", "function"):
                        function_name = e.get("action", {}).get("functionName")
                        _invoke_function(function_name, {"e": e})
                        results.append({"event": condition, "action": f"function_invoked:{function_name}"})
                    
                    # Handle feedback
                    if "feedback" in e.get("action", {}) and USE_FEEDBACK:
                        feedback_config = e["action"]["feedback"]
                        feedback_payload = {
                            "detail": {
                                "digitalTwinName": DIGITAL_TWIN_INFO["config"]["digital_twin_name"],
                                "iotDeviceId": feedback_config.get("iotDeviceId"),
                                "payload": feedback_config.get("payload")
                            }
                        }
                        _send_feedback(feedback_payload)
                        results.append({"event": condition, "feedback": "sent"})
                
            except Exception as ex:
                logging.error(f"Event check failed for {e}: {ex}")
                results.append({"event": str(e), "error": str(ex)})
        
        return func.HttpResponse(
            json.dumps({"checked": len(config_events), "results": results}),
            status_code=200,
            mimetype="application/json"
        )
        
    except Exception as e:
        logging.error(f"Event Checker Error: {e}")
        return func.HttpResponse(
            json.dumps({"error": str(e)}),
            status_code=500,
            mimetype="application/json"
        )